# Generated content DO NOT EDIT
from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Sequence
from os import PathLike
from candle.typing import _ArrayLike, Device
from candle import Tensor, DType

@staticmethod
def silu(tensor: Tensor):
    """
    Applies the Sigmoid Linear Unit (SiLU) function to a given tensor.
    """
    pass

@staticmethod
def softmax(tensor: Tensor, dim: int):
    """
    Applies the Softmax function to a given tensor.
    """
    pass
